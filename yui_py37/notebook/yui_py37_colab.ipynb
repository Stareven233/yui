{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-0864_dB5Mv",
        "outputId": "233c44ec-b337-4dc8-ade8-a64753d028d4"
      },
      "outputs": [],
      "source": [
        "!lsb_release -a\n",
        "# !cat /etc/shells\n",
        "# !echo $SHELL\n",
        "!cat /proc/cpuinfo \n",
        "!free -m\n",
        "!nvidia-smi\n",
        "\n",
        "%pip install --upgrade pip\n",
        "%pip install mir_eval librosa pydub\n",
        "# %pip install torch==1.10.2 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "%pip install note_seq==0.0.3 transformers  scikit-learn  pandas\n",
        "\n",
        "# !git clone https://github.com/NVIDIA/apex\n",
        "# %pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" /content/apex/\n",
        "# # 使用 apex.normalization.FusedRMSNorm 替代 T5LayerNorm 加快计算\n",
        "# 安装要将近20分钟，还是算了吧"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNq5APb7EIHR",
        "outputId": "31e1a497-4eb5-4d68-c6a2-ea6b700cbfa4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "\n",
        "# # %set_env KAGGLE_CONFIG_DIR=/content/drive/MyDrive/kaggle\n",
        "# # # 替代export设置kaggle文件夹的位置，路径不能有引号\n",
        "# # !kaggle datasets download -d stareven233/maestrov200\n",
        "# # # 下载后拉到云盘里，省得以后再下载\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "!unzip /content/drive/MyDrive/yui_py37.zip -d /content/\n",
        "!unzip /content/drive/MyDrive/datasets/maestrov200.zip -d /content/maestro/\n",
        "sys.path.insert(0, r'/content/yui_py37')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i2eTb9HB5M0"
      },
      "outputs": [],
      "source": [
        "# 升级MAESTROv2.0.0 -> 3.0.0 且 输出gpu信息\n",
        "import utils\n",
        "import preprocessors\n",
        "\n",
        "\n",
        "preprocessors.upgrade_maestro(r'/content/maestro/')\n",
        "utils.show_gpu_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import T5ForConditionalGeneration, T5Config\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "\n",
        "from datasets import MaestroDataset2, MaestroSampler2, collate_fn\n",
        "import vocabularies\n",
        "import config\n",
        "from config.data import YuiConfigPro\n",
        "import utils\n",
        "from train import train, evaluate\n",
        "\n",
        "resume = True\n",
        "\n",
        "\n",
        "# config\n",
        "cf = YuiConfigPro(\n",
        "  DATASET_DIR=r'/content/maestro/',\n",
        "  DATAMETA_NAME=r'maestro-v3.0.0.csv',\n",
        "  WORKSPACE=r'/content/drive/MyDrive/',\n",
        "  # WORKSPACE=r'/content/',\n",
        "  CUDA=True,\n",
        "  NUM_EPOCHS=2,\n",
        "  NUM_WORKERS=2,\n",
        "  BATCH_SIZE=12,\n",
        "  TRAIN_ITERATION=100,\n",
        ")\n",
        "# 经常分到 k80 显存12GB，batch_size不能太大\n",
        "\n",
        "# Arugments & parameters\n",
        "workspace = cf.WORKSPACE\n",
        "batch_size = cf.BATCH_SIZE\n",
        "device = torch.device('cuda') if cf.CUDA and torch.cuda.is_available() else torch.device('cpu')\n",
        "num_workers = cf.NUM_WORKERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checkpoint & Log\n",
        "# 单独放置，否则多次创建logger会有多个重复输出\n",
        "\n",
        "checkpoints_dir = os.path.join(workspace, 'checkpoints')\n",
        "utils.create_folder(checkpoints_dir)\n",
        "logs_dir = os.path.join(workspace, 'logs')\n",
        "utils.create_logging(logs_dir, f'train', filemode='w', with_time=True)\n",
        "resume_checkpoint_path = os.path.join(checkpoints_dir, 'model_resume.pt')\n",
        "best_checkpoint_path = os.path.join(checkpoints_dir, 'model_best.pt')\n",
        "statistics_path = os.path.join(checkpoints_dir, 'statistics.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Codec & Vocabulary\n",
        "codec = vocabularies.build_codec(cf)\n",
        "vocabulary = vocabularies.Vocabulary(cf, codec.num_classes, extra_ids=cf.EXTRA_IDS)\n",
        "t5_config_map = config.build_t5_config(\n",
        "  vocab_size=vocabulary.vocab_size,\n",
        "  num_layers=3,\n",
        "  num_decoder_layers=3,\n",
        ")\n",
        "# 简化模型，否则根本训练不动\n",
        "\n",
        "logging.info(cf)  \n",
        "if device.type == 'cuda':\n",
        "  logging.info('Using GPU.')\n",
        "  logging.info(f'GPU number: {torch.cuda.device_count()}')\n",
        "else:\n",
        "  logging.info('Using CPU.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset\n",
        "meta_path = os.path.join(cf.DATASET_DIR, cf.DATAMETA_NAME)\n",
        "\n",
        "train_sampler = MaestroSampler2(meta_path, 'train', batch_size=batch_size, config=cf, max_iter_num=cf.TRAIN_ITERATION)\n",
        "train_dataset = MaestroDataset2(cf.DATASET_DIR, cf, codec, vocabulary, meta_file=cf.DATAMETA_NAME)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_sampler=train_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "validate_sampler = MaestroSampler2(meta_path, 'validation', batch_size=batch_size, config=cf, max_iter_num=-1)\n",
        "validate_loader = DataLoader(dataset=train_dataset, batch_sampler=validate_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)\n",
        "# pin_memory: 锁页内存，不会与虚存进行交换，转到gpu时快一些，但很容易超出gpu显存\n",
        "\n",
        "# Model\n",
        "t5_config = T5Config.from_dict(t5_config_map)\n",
        "model = T5ForConditionalGeneration(config=t5_config)\n",
        "logging.info(f'The model has {model.num_parameters():,} trainable parameters')\n",
        "# 17,896 for dev; 48,626,048 for pro; while T5-Small has 60 million parameters\n",
        "\n",
        "\n",
        "# Early stop\n",
        "early_stopping = utils.EarlyStopping(\n",
        "  best_path=best_checkpoint_path,\n",
        "  resume_path=resume_checkpoint_path,\n",
        "  patience=cf.OVERFIT_PATIENCE, \n",
        "  verbose=True\n",
        ")\n",
        "\n",
        "# Resume training\n",
        "resume_epoch = 0\n",
        "learning_rate = cf.LEARNING_RATE\n",
        "statistics = {\n",
        "  'epoch': 0,\n",
        "  'train_loss': [],\n",
        "  'eval_loss': []\n",
        "}\n",
        "\n",
        "if not resume:\n",
        "  ...\n",
        "  # 从头开始训练模型\n",
        "elif not os.path.isfile(resume_checkpoint_path):\n",
        "  logging.info(f'resume_checkpoint_path={resume_checkpoint_path} does not exist, train from scratch')\n",
        "elif not os.path.isfile(statistics_path):\n",
        "  logging.info(f'statistics_path={statistics_path} does not exist, train from scratch')\n",
        "else:\n",
        "  statistics = torch.load(statistics_path)\n",
        "  # 单独保存后面数据分析读取方便些\n",
        "  # raise FileNotFoundError(f'resume_checkpoint_path={resume_checkpoint_path} does not exist')\n",
        "  checkpoint = torch.load(resume_checkpoint_path)\n",
        "  # 以TRAIN_ITERATION为单位保存checkpoint\n",
        "  early_stopping.load_state_dict(checkpoint['early_stopping'])\n",
        "\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  train_sampler.load_state_dict(checkpoint['sampler'])\n",
        "  validate_sampler.epoch = train_sampler.epoch\n",
        "  # 二者epoch一致\n",
        "  resume_epoch = checkpoint['epoch']\n",
        "  learning_rate = checkpoint['learning_rate'][-1]\n",
        "  # scheduler.get_lr 拿到的lr是个列表\n",
        "  logging.info(f'resume training with epoch={resume_epoch}, lr={learning_rate}')\n",
        "\n",
        "# Loss function\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=cf.PAD_ID)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = Adafactor(model.parameters(), lr=learning_rate, scale_parameter=False, relative_step=False, warmup_init=False)\n",
        "scheduler = AdafactorSchedule(optimizer, learning_rate)\n",
        "\n",
        "model.to(device)\n",
        "epoch = resume_epoch\n",
        "loop_start_time = time.time()\n",
        "start_time = time.time()\n",
        "assert epoch == train_sampler.epoch, f'resume training: epoch={epoch} != train_sampler.epoch={train_sampler.epoch}'\n",
        "logging.info(f'-------train loop starts, start_time={start_time:.3f}s-------')\n",
        "\n",
        "# for epoch in range(resume_epoch, cf.NUM_EPOCHS):\n",
        "while epoch < cf.NUM_EPOCHS:\n",
        "  train_loss = train(model, device, train_loader, criterion, optimizer, scheduler)\n",
        "  statistics['train_loss'].append(train_loss)\n",
        "  current_lr = scheduler.get_lr()\n",
        "\n",
        "  # 训练数据完整采样一轮\n",
        "  if train_sampler.epoch > epoch:\n",
        "    validate_sampler.reset_state()\n",
        "    validate_loss = evaluate(model, device, validate_loader, criterion)\n",
        "    statistics['eval_loss'].append(train_loss)\n",
        "    # 等train数据完整过了一遍再进行评估\n",
        "    logging.info(\n",
        "      f'epoch={epoch} finish, time={time.time()-start_time:.3f}s, train_loss={train_loss}, validate_loss={validate_loss}'\n",
        "      f', with lr={current_lr}'\n",
        "    )\n",
        "\n",
        "    early_stopping(validate_loss)\n",
        "    if early_stopping.stop:\n",
        "      logging.info(f'early stoping')\n",
        "      break\n",
        "\n",
        "    epoch += 1\n",
        "    start_time = time.time()\n",
        "    train_sampler.reset_state()\n",
        "  \n",
        "  # Save model\n",
        "  statistics['epoch'] = epoch\n",
        "  checkpoint = {\n",
        "    'epoch': epoch,\n",
        "    'model': model.state_dict(),\n",
        "    'sampler': train_sampler.state_dict(),\n",
        "    'learning_rate': current_lr,\n",
        "    'early_stopping': early_stopping.state_dict(),\n",
        "  }\n",
        "  torch.save(checkpoint, resume_checkpoint_path)\n",
        "  torch.save(statistics, statistics_path)\n",
        "  logging.info(f'save model and statistics to {checkpoints_dir}')\n",
        "logging.info(f'-------train loop ends, time={time.time()-loop_start_time:.3f}s-------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm /content/logs -r"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "yui_colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d5c8e674f5dfa726cbc4d7a25209bb75f43fdf268afb841d4cc164f7f4d4aeee"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
