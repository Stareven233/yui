{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#title install python 3.9\n\n!lsb_release -a\n# !cat /etc/shells\n# !echo $SHELL\n!cat /proc/cpuinfo \n!free -m\n!nvidia-smi\n\n%pip install --upgrade pip\n%pip install mir_eval librosa pydub\n# %pip install torch==1.10.2 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n%pip install note_seq==0.0.3 transformers==4.17.0  scikit-learn  pandas","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-14T02:51:03.130487Z","iopub.execute_input":"2022-04-14T02:51:03.130943Z","iopub.status.idle":"2022-04-14T02:52:12.835577Z","shell.execute_reply.started":"2022-04-14T02:51:03.130809Z","shell.execute_reply":"2022-04-14T02:52:12.834437Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import sys\nimport shutil\n\n!rm /kaggle/working/yui/ -r\nshutil.copytree(r'../input/yui-code/yui_py37', r'/kaggle/working/yui')\nsys.path.insert(0, r'/kaggle/working/yui')\nsys.path.insert(0, r'/kaggle/working/yui/yui')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T02:52:35.536233Z","iopub.execute_input":"2022-04-14T02:52:35.536587Z","iopub.status.idle":"2022-04-14T02:52:36.330030Z","shell.execute_reply.started":"2022-04-14T02:52:35.536556Z","shell.execute_reply":"2022-04-14T02:52:36.328675Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport logging\nimport preprocessors\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import T5ForConditionalGeneration, T5Config\nfrom transformers.optimization import Adafactor, AdafactorSchedule\n\nfrom datasets import MaestroDataset2, MaestroSampler2, collate_fn\nimport vocabularies\nimport config\nfrom config.data import YuiConfigPro\nimport utils\nfrom train import train, evaluate\n\nresume = False\n\n\n# config\ncf = YuiConfigPro(\n  DATASET_DIR=r'/kaggle/input/themaestrodatasetv2/maestro-v2.0.0/',\n  DATAMETA_NAME=r'maestro-v3.0.0.csv',\n  WORKSPACE=r'/kaggle/working/',\n  # WORKSPACE=r'/content/',\n  CUDA=True,\n  NUM_EPOCHS=2,\n  NUM_WORKERS=2,\n  BATCH_SIZE=16,\n  TRAIN_ITERATION=50,\n)\n# Codec & Vocabulary\ncodec = vocabularies.build_codec(cf)\nvocabulary = vocabularies.Vocabulary(cf, codec.num_classes, extra_ids=cf.EXTRA_IDS)\nt5_config_map = config.build_t5_config(\n  vocab_size=vocabulary.vocab_size,\n  num_layers=3,\n  num_decoder_layers=3,\n)\n# 简化模型，否则根本训练不动\n\n# 升级MAESTROv2.0.0 -> 3.0.0 且 输出gpu信息\nmeta_folder = r'/kaggle/working/maestro/'\nutils.create_folder(meta_folder)\npreprocessors.upgrade_maestro2(cf.DATASET_DIR, meta_folder)\nutils.show_gpu_info()\n\n\n# Arugments & parameters\nworkspace = cf.WORKSPACE\nbatch_size = cf.BATCH_SIZE\ndevice = torch.device('cuda') if cf.CUDA and torch.cuda.is_available() else torch.device('cpu')\nnum_workers = cf.NUM_WORKERS\n\n# Checkpoint & Log\ncheckpoints_dir = os.path.join(workspace, 'checkpoints')\nutils.create_folder(checkpoints_dir)\nlogs_dir = os.path.join(workspace, 'logs')\nutils.create_logging(logs_dir, f'train', filemode='w', with_time=True)\nresume_checkpoint_path = os.path.join(checkpoints_dir, 'model_resume.pt')\nbest_checkpoint_path = os.path.join(checkpoints_dir, 'model_best.pt')\nstatistics_path = os.path.join(checkpoints_dir, 'statistics.pt')\n\nlogging.info(cf)  \nif device.type == 'cuda':\n  logging.info('Using GPU.')\n  logging.info(f'GPU number: {torch.cuda.device_count()}')\nelse:\n  logging.info('Using CPU.')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-14T02:52:42.909295Z","iopub.execute_input":"2022-04-14T02:52:42.910062Z","iopub.status.idle":"2022-04-14T02:52:52.792396Z","shell.execute_reply.started":"2022-04-14T02:52:42.910023Z","shell.execute_reply":"2022-04-14T02:52:52.791331Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Dataset\nmeta_path = os.path.join(meta_folder, cf.DATAMETA_NAME)\n\ntrain_sampler = MaestroSampler2(meta_path, 'train', batch_size=batch_size, config=cf, max_iter_num=cf.TRAIN_ITERATION)\ntrain_dataset = MaestroDataset2(cf.DATASET_DIR, cf, codec, vocabulary, meta_folder=meta_folder, meta_file=cf.DATAMETA_NAME)\ntrain_loader = DataLoader(dataset=train_dataset, batch_sampler=train_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=False)\n\nvalidate_sampler = MaestroSampler2(meta_path, 'validation', batch_size=batch_size, config=cf, max_iter_num=-1)\nvalidate_loader = DataLoader(dataset=train_dataset, batch_sampler=validate_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=False)\n# pin_memory: 锁页内存，不会与虚存进行交换，转到gpu时快一些，但很容易超出gpu显存\n\n# Model\nt5_config = T5Config.from_dict(t5_config_map)\nmodel = T5ForConditionalGeneration(config=t5_config)\nlogging.info(f'The model has {model.num_parameters():,} trainable parameters')\n# 17,896 for dev; 48,626,048 for pro; while T5-Small has 60 million parameters\n\n\n# Early stop\nearly_stopping = utils.EarlyStopping(\n  best_path=best_checkpoint_path,\n  resume_path=resume_checkpoint_path,\n  patience=cf.OVERFIT_PATIENCE, \n  verbose=True\n)\n\n# Resume training\nresume_epoch = 0\nlearning_rate = cf.LEARNING_RATE\nstatistics = {\n  'epoch': 0,\n  'train_loss': [],\n  'eval_loss': []\n}\n\nif not resume:\n  ...\n  # 从头开始训练模型\nelif not os.path.isfile(resume_checkpoint_path):\n  logging.info(f'resume_checkpoint_path={resume_checkpoint_path} does not exist, train from scratch')\nelif not os.path.isfile(statistics_path):\n  logging.info(f'statistics_path={statistics_path} does not exist, train from scratch')\nelse:\n  statistics = torch.load(statistics_path)\n  # 单独保存后面数据分析读取方便些\n  # raise FileNotFoundError(f'resume_checkpoint_path={resume_checkpoint_path} does not exist')\n  checkpoint = torch.load(resume_checkpoint_path)\n  # 以TRAIN_ITERATION为单位保存checkpoint\n  early_stopping.load_state_dict(checkpoint['early_stopping'])\n\n  model.load_state_dict(checkpoint['model'])\n  train_sampler.load_state_dict(checkpoint['sampler'])\n  validate_sampler.epoch = train_sampler.epoch\n  # 二者epoch一致\n  resume_epoch = checkpoint['epoch']\n  learning_rate = checkpoint['learning_rate'][-1]\n  # scheduler.get_lr 拿到的lr是个列表\n  logging.info(f'resume training with epoch={resume_epoch}, lr={learning_rate}')\n\n# Loss function\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=cf.PAD_ID)\n\n# Optimizer\noptimizer = Adafactor(model.parameters(), lr=learning_rate, scale_parameter=False, relative_step=False, warmup_init=False)\nscheduler = AdafactorSchedule(optimizer, learning_rate)\n\nmodel.to(device)\nepoch = resume_epoch\nloop_start_time = time.time()\nstart_time = time.time()\nassert epoch == train_sampler.epoch, f'resume training: epoch={epoch} != train_sampler.epoch={train_sampler.epoch}'\nlogging.info(f'-------train loop starts, start_time={start_time:.3f}s-------')\n\n# for epoch in range(resume_epoch, cf.NUM_EPOCHS):\nwhile epoch < cf.NUM_EPOCHS:\n  train_loss = train(model, device, train_loader, criterion, optimizer, scheduler)\n  statistics['train_loss'].append(train_loss)\n  current_lr = scheduler.get_lr()\n\n  # 训练数据完整采样一轮\n  if train_sampler.epoch > epoch:\n    validate_sampler.reset_state()\n    validate_loss = evaluate(model, device, validate_loader, criterion)\n    statistics['eval_loss'].append(train_loss)\n    # 等train数据完整过了一遍再进行评估\n    logging.info(\n      f'epoch={epoch} finish, time={time.time()-start_time:.3f}s, train_loss={train_loss}, validate_loss={validate_loss}'\n      f', with lr={current_lr}'\n    )\n\n    early_stopping(validate_loss)\n    if early_stopping.stop:\n      logging.info(f'early stoping')\n      break\n\n    epoch += 1\n    start_time = time.time()\n    train_sampler.reset_state()\n  \n  # Save model\n  statistics['epoch'] = epoch\n  checkpoint = {\n    'epoch': epoch,\n    'model': model.state_dict(),\n    'sampler': train_sampler.state_dict(),\n    'learning_rate': current_lr,\n    'early_stopping': early_stopping.state_dict(),\n  }\n  torch.save(checkpoint, resume_checkpoint_path)\n  torch.save(statistics, statistics_path)\n  logging.info(f'save model and statistics to {checkpoints_dir}')\nlogging.info(f'-------train loop ends, time={time.time()-loop_start_time:.3f}s-------')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-14T02:53:01.473960Z","iopub.execute_input":"2022-04-14T02:53:01.474256Z","iopub.status.idle":"2022-04-14T02:56:30.931609Z","shell.execute_reply.started":"2022-04-14T02:53:01.474222Z","shell.execute_reply":"2022-04-14T02:56:30.927918Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport logging\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import T5ForConditionalGeneration, T5Config\nfrom transformers.optimization import Adafactor, AdafactorSchedule\n\nfrom datasets import MaestroDataset2, MaestroSampler2, collate_fn\nimport vocabularies\nimport config\nfrom config.data import YuiConfigPro\nimport utils\nfrom train import train, evaluate\n\nresume = True\n\n\n# config\ncf = YuiConfigPro(\n  DATASET_DIR=r'/content/maestro/',\n  DATAMETA_NAME=r'maestro-v3.0.0.csv',\n  WORKSPACE=r'/content/drive/MyDrive/',\n  # WORKSPACE=r'/content/',\n  CUDA=True,\n  NUM_EPOCHS=2,\n  NUM_WORKERS=2,\n  BATCH_SIZE=16,\n  TRAIN_ITERATION=50,\n)\n# Codec & Vocabulary\ncodec = vocabularies.build_codec(cf)\nvocabulary = vocabularies.Vocabulary(cf, codec.num_classes, extra_ids=cf.EXTRA_IDS)\nt5_config = config.build_t5_config(\n  vocab_size=vocabulary.vocab_size,\n  num_layers=3,\n  num_decoder_layers=3,\n)\n# 简化模型，否则根本训练不动\n\n# Arugments & parameters\nworkspace = cf.WORKSPACE\nbatch_size = cf.BATCH_SIZE\ndevice = torch.device('cuda') if cf.CUDA and torch.cuda.is_available() else torch.device('cpu')\nnum_workers = cf.NUM_WORKERS\n\n# Checkpoint & Log\ncheckpoints_dir = os.path.join(workspace, 'checkpoints')\nutils.create_folder(checkpoints_dir)\nlogs_dir = os.path.join(workspace, 'logs')\nutils.create_logging(logs_dir, f'train', filemode='w', with_time=True)\nresume_checkpoint_path = os.path.join(checkpoints_dir, 'model_resume.pt')\nbest_checkpoint_path = os.path.join(checkpoints_dir, 'model_best.pt')\nstatistics_path = os.path.join(checkpoints_dir, 'statistics.pt')\n\nlogging.info(cf)  \nif device.type == 'cuda':\n  logging.info('Using GPU.')\n  logging.info(f'GPU number: {torch.cuda.device_count()}')\nelse:\n  logging.info('Using CPU.')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T11:30:06.642395Z","iopub.execute_input":"2022-04-11T11:30:06.643031Z","iopub.status.idle":"2022-04-11T11:30:08.015763Z","shell.execute_reply.started":"2022-04-11T11:30:06.642993Z","shell.execute_reply":"2022-04-11T11:30:08.014888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset\nmeta_path = os.path.join(cf.DATASET_DIR, cf.DATAMETA_NAME)\n\ntrain_sampler = MaestroSampler2(meta_path, 'train', batch_size=batch_size, config=cf, max_iter_num=cf.TRAIN_ITERATION)\ntrain_dataset = MaestroDataset2(cf.DATASET_DIR, cf, codec, vocabulary, meta_file=cf.DATAMETA_NAME)\ntrain_loader = DataLoader(dataset=train_dataset, batch_sampler=train_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)\n\nvalidate_sampler = MaestroSampler2(meta_path, 'validation', batch_size=batch_size, config=cf, max_iter_num=-1)\nvalidate_loader = DataLoader(dataset=train_dataset, batch_sampler=validate_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)\n# pin_memory: 锁页内存，不会与虚存进行交换，转到gpu时快一些，但很容易超出gpu显存\n\n# Model\nt5_config = T5Config.from_dict(t5_config)\nmodel = T5ForConditionalGeneration(config=t5_config)\nlogging.info(f'The model has {model.num_parameters():,} trainable parameters')\n# 17,896 for dev; 48,626,048 for pro; while T5-Small has 60 million parameters\n\n# Early stop\nearly_stopping = utils.EarlyStopping(\n  best_path=best_checkpoint_path,\n  resume_path=resume_checkpoint_path,\n  patience=cf.OVERFIT_PATIENCE, \n  verbose=True\n)\n\n# Resume training\nresume_epoch = 0\nlearning_rate = cf.LEARNING_RATE\nstatistics = {\n  'epoch': 0,\n  'train_loss': [],\n  'eval_loss': []\n}\n\nif not resume:\n  ...\n  # 从头开始训练模型\nelif not os.path.isfile(resume_checkpoint_path):\n  logging.info(f'{resume_checkpoint_path=} does not exist, train from scratch')\nelif not os.path.isfile(statistics_path):\n  logging.info(f'{statistics_path=} does not exist, train from scratch')\nelse:\n  statistics = torch.load(statistics_path)\n  # 单独保存后面数据分析读取方便些\n  # raise FileNotFoundError(f'{resume_checkpoint_path=} does not exist')\n  checkpoint = torch.load(resume_checkpoint_path)\n  # 以TRAIN_ITERATION为单位保存checkpoint\n  early_stopping.load_state_dict(checkpoint['early_stopping'])\n\n  model.load_state_dict(checkpoint['model'])\n  train_sampler.load_state_dict(checkpoint['sampler'])\n  validate_sampler.epoch = train_sampler.epoch\n  # 二者epoch一致\n  resume_epoch = checkpoint['epoch']\n  learning_rate = checkpoint['learning_rate'][-1]\n  # scheduler.get_lr 拿到的lr是个列表\n  logging.info(f'resume training with epoch={resume_epoch}, lr={learning_rate}')\n\n# Loss function\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=cf.PAD_ID)\n\n# Optimizer\noptimizer = Adafactor(model.parameters(), lr=learning_rate, scale_parameter=False, relative_step=False, warmup_init=False)\nscheduler = AdafactorSchedule(optimizer, learning_rate)\n\nmodel.to(device)\nepoch = resume_epoch\nloop_start_time = time.time()\nstart_time = time.time()\nassert epoch == train_sampler.epoch, f'resume training: {epoch=} != {train_sampler.epoch=}'\nlogging.info(f'-------train loop starts, {start_time=:.3f}s-------')\n\n# for epoch in range(resume_epoch, cf.NUM_EPOCHS):\nwhile epoch < cf.NUM_EPOCHS:\n  train_loss = train(model, device, train_loader, criterion, optimizer, scheduler)\n  statistics['train_loss'].append(train_loss)\n  current_lr = scheduler.get_lr()\n\n  # 训练数据完整采样一轮\n  if train_sampler.epoch > epoch:\n    validate_sampler.reset_state()\n    validate_loss = evaluate(model, device, validate_loader, criterion)\n    statistics['eval_loss'].append(train_loss)\n    # 等train数据完整过了一遍再进行评估\n    logging.info(\n      f'{epoch=} finish, time={time.time()-start_time:.3f}s, {train_loss=}, {validate_loss=}'\n      f', with lr={current_lr}'\n    )\n\n    early_stopping(validate_loss)\n    if early_stopping.stop:\n      logging.info(f'early stoping')\n      break\n\n    epoch += 1\n    start_time = time.time()\n    train_sampler.reset_state()\n  \n  # Save model\n  statistics['epoch'] = epoch\n  checkpoint = {\n    'epoch': epoch,\n    'model': model.state_dict(),\n    'sampler': train_sampler.state_dict(),\n    'learning_rate': current_lr,\n    'early_stopping': early_stopping.state_dict(),\n  }\n  torch.save(checkpoint, resume_checkpoint_path)\n  torch.save(statistics, statistics_path)\n  logging.info(f'save model and statistics to {checkpoints_dir}')\nlogging.info(f'-------train loop ends, time={time.time()-loop_start_time:.3f}s-------')\n","metadata":{},"execution_count":null,"outputs":[]}]}