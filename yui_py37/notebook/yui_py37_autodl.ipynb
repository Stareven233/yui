{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-0864_dB5Mv",
        "outputId": "233c44ec-b337-4dc8-ade8-a64753d028d4"
      },
      "outputs": [],
      "source": [
        "# !ls /root\n",
        "\n",
        "!cat /proc/cpuinfo \n",
        "!free -m\n",
        "!nvidia-smi\n",
        "\n",
        "# %pip install --upgrade pip\n",
        "!apt update\n",
        "!apt install libsndfile1 -y\n",
        "!apt install ffmpeg -y\n",
        "%pip install mir_eval librosa h5py kaggle\n",
        "%pip install note_seq==0.0.3 transformers  scikit-learn  pandas\n",
        "\n",
        "!git clone https://gitclone.com/github.com/NVIDIA/apex.git\n",
        "%pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" /root/apex/\n",
        "!rm /root/apex -r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm /root/yui_py37 -r\n",
        "!unzip /root/yui_py37.zip -d /root/\n",
        "\n",
        "# %set_env KAGGLE_CONFIG_DIR=/root/kaggle\n",
        "# # 替代export设置kaggle文件夹的位置，路径不能有引号\n",
        "# !kaggle config set -n path -v /root/autodl-tmp/\n",
        "# !kaggle datasets download -d stareven233/maestrov300-hdf5\n",
        "# !unzip /root/autodl-tmp/maestrov300-hdf5.zip -d /root/autodl-tmp/maestro-v3.0.0_hdf5/\n",
        "# !rm /root/autodl-tmp/maestrov300-hdf5.zip\n",
        "# 直接ftp上传得了\n",
        "!unzip /root/autodl-tmp/checkpoints.zip -d /root/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import math\n",
        "import sys\n",
        "sys.path.insert(0, r'/root/yui_py37')\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import T5ForConditionalGeneration, T5Config\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "\n",
        "from datasets import MaestroDataset3, MaestroSampler2, collate_fn\n",
        "import vocabularies\n",
        "import config\n",
        "from config.data import YuiConfigPro\n",
        "import utils\n",
        "from train import train, evaluate\n",
        "\n",
        "resume = True\n",
        "\n",
        "\n",
        "# config\n",
        "cf = YuiConfigPro(\n",
        "  DATASET_DIR=r'/root/autodl-tmp/maestro-v3.0.0_hdf5/',\n",
        "  DATAMETA_NAME=r'maestro-v3.0.0.csv',\n",
        "  WORKSPACE=r'/root/',\n",
        "  CUDA=True,\n",
        "  NUM_EPOCHS=30,\n",
        "  NUM_WORKERS=4,\n",
        "  BATCH_SIZE=8,\n",
        "  TRAIN_ITERATION=1800,\n",
        ")\n",
        "\n",
        "# Arugments & parameters\n",
        "workspace = cf.WORKSPACE\n",
        "batch_size = cf.BATCH_SIZE\n",
        "device = torch.device('cuda') if cf.CUDA and torch.cuda.is_available() else torch.device('cpu')\n",
        "num_workers = cf.NUM_WORKERS\n",
        "\n",
        "class Adafactor2(Adafactor):\n",
        "  def __init__(\n",
        "    self,\n",
        "    params,\n",
        "    lr=None,\n",
        "    eps=(1e-30, 1e-3),\n",
        "    clip_threshold=1.0,\n",
        "    decay_rate=-0.8,\n",
        "    beta1=None,\n",
        "    weight_decay=0.0,\n",
        "    scale_parameter=True,\n",
        "    relative_step=True,\n",
        "    warmup_init=False,\n",
        "  ):\n",
        "    super().__init__(params, lr, eps, clip_threshold, decay_rate, beta1, weight_decay, scale_parameter, relative_step, warmup_init)\n",
        "\n",
        "  @staticmethod\n",
        "  def _get_lr(param_group, param_state):\n",
        "    rel_step_sz = param_group[\"lr\"]\n",
        "    if param_group[\"relative_step\"]:\n",
        "      min_step = 1e-6 * param_state[\"step\"] if param_group[\"warmup_init\"] else 1e-3\n",
        "      exp_lr = math.exp(-(6.45 + param_state[\"step\"] / 3e4))\n",
        "      # 这个值将在step=[1500,30000]从1.5e-3降到9.6e-4\n",
        "      rel_step_sz = min(min_step, exp_lr)\n",
        "    if param_group[\"scale_parameter\"]:\n",
        "      rel_step_sz *= max(param_group[\"eps\"][1], param_state[\"RMS\"])\n",
        "    return rel_step_sz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checkpoint & Log\n",
        "# 单独放置，否则多次创建logger会有多个重复输出\n",
        "\n",
        "checkpoints_dir = os.path.join(workspace, 'checkpoints')\n",
        "utils.create_folder(checkpoints_dir)\n",
        "logs_dir = os.path.join(workspace, 'logs')\n",
        "utils.create_logging(logs_dir, f'train', filemode='w', with_time=True)\n",
        "resume_checkpoint_path = os.path.join(checkpoints_dir, 'model_resume.pt')\n",
        "best_checkpoint_path = os.path.join(checkpoints_dir, 'model_best.pt')\n",
        "statistics_path = os.path.join(checkpoints_dir, 'statistics.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Codec & Vocabulary\n",
        "codec = vocabularies.build_codec(cf)\n",
        "vocabulary = vocabularies.Vocabulary(cf, codec.num_classes, extra_ids=cf.EXTRA_IDS)\n",
        "t5_config_map = config.build_t5_config(\n",
        "  d_model=cf.NUM_MEL_BINS,\n",
        "  vocab_size=vocabulary.vocab_size,\n",
        "  max_length=cf.MAX_TARGETS_LENGTH,\n",
        ")\n",
        "# 简化模型，否则根本训练不动\n",
        "utils.show_gpu_info()\n",
        "\n",
        "logging.info(cf) \n",
        "if device.type == 'cuda':\n",
        "  logging.info('Using GPU.')\n",
        "  logging.info(f'GPU number: {torch.cuda.device_count()}')\n",
        "else:\n",
        "  logging.info('Using CPU.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset\n",
        "meta_path = os.path.join(cf.DATASET_DIR, cf.DATAMETA_NAME)\n",
        "\n",
        "train_sampler = MaestroSampler2(meta_path, 'train', batch_size=batch_size, config=cf, max_iter_num=cf.TRAIN_ITERATION)\n",
        "train_dataset = MaestroDataset3(cf.DATASET_DIR, cf, codec, vocabulary, meta_file=cf.DATAMETA_NAME)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_sampler=train_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "validate_sampler = MaestroSampler2(meta_path, 'validation', batch_size=batch_size, config=cf, max_iter_num=-1)\n",
        "validate_loader = DataLoader(dataset=train_dataset, batch_sampler=validate_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)\n",
        "# pin_memory: 锁页内存，不会与虚存进行交换，转到gpu时快一些，但很容易超出gpu显存\n",
        "\n",
        "# Model\n",
        "t5_config = T5Config.from_dict(t5_config_map)\n",
        "logging.info(t5_config)\n",
        "model = T5ForConditionalGeneration(config=t5_config)\n",
        "logging.info(f'The model has {model.num_parameters():,} trainable parameters')\n",
        "# 17,896 for dev; 48,626,048 for pro; while T5-Small has 60 million parameters\n",
        "\n",
        "# Early stop\n",
        "early_stopping = utils.EarlyStopping(\n",
        "  best_path=best_checkpoint_path,\n",
        "  resume_path=resume_checkpoint_path,\n",
        "  patience=cf.OVERFIT_PATIENCE, \n",
        "  verbose=True\n",
        ")\n",
        "\n",
        "# Resume training\n",
        "resume_epoch = 0\n",
        "learning_rate = cf.LEARNING_RATE\n",
        "statistics = {\n",
        "  'epoch': 0,\n",
        "  'train_loss': [],\n",
        "  'eval_loss': []\n",
        "}\n",
        "\n",
        "# Loss function\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=cf.PAD_ID)\n",
        "\n",
        "# Optimizer\n",
        "# optimizer = Adafactor(model.parameters(), lr=learning_rate, scale_parameter=False, relative_step=False, warmup_init=False)\n",
        "optimizer = Adafactor2(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
        "scheduler = AdafactorSchedule(optimizer, learning_rate)\n",
        "\n",
        "if not resume:\n",
        "  ...\n",
        "  # 从头开始训练模型\n",
        "elif not os.path.isfile(resume_checkpoint_path):\n",
        "  logging.info(f'resume_checkpoint_path={resume_checkpoint_path} does not exist, train from scratch')\n",
        "elif not os.path.isfile(statistics_path):\n",
        "  logging.info(f'statistics_path={statistics_path} does not exist, train from scratch')\n",
        "else:\n",
        "  statistics = torch.load(statistics_path)\n",
        "  # 单独保存后面数据分析读取方便些\n",
        "  # raise FileNotFoundError(f'resume_checkpoint_path={resume_checkpoint_path} does not exist')\n",
        "  checkpoint = torch.load(resume_checkpoint_path)\n",
        "  # 以TRAIN_ITERATION为单位保存checkpoint\n",
        "  early_stopping.load_state_dict(checkpoint['early_stopping'])\n",
        "\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  train_sampler.load_state_dict(checkpoint['sampler'])\n",
        "  validate_sampler.epoch = train_sampler.epoch\n",
        "  # 二者epoch一致\n",
        "  resume_epoch = checkpoint['epoch']\n",
        "  # scheduler.get_lr 拿到的lr是个列表\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  logging.info(f'resume training with epoch={resume_epoch}')\n",
        "  logging.info(f'statistics = {statistics}')\n",
        "\n",
        "model.to(device)\n",
        "epoch = resume_epoch\n",
        "loop_start_time = time.time()\n",
        "start_time = time.time()\n",
        "logging.info(f'-------train loop starts, start_time={start_time:.3f}s-------')\n",
        "\n",
        "# for epoch in range(resume_epoch, cf.NUM_EPOCHS):\n",
        "while epoch < cf.NUM_EPOCHS:\n",
        "  train_loss = train(model, device, train_loader, criterion, optimizer, scheduler, accumulation_steps=cf.accumulation_steps)\n",
        "  statistics['train_loss'].append(train_loss)\n",
        "  current_lr = scheduler.get_lr()\n",
        "\n",
        "  # 训练数据完整采样一轮\n",
        "  if train_sampler.epoch > epoch:\n",
        "    validate_sampler.reset_state()\n",
        "    validate_loss = evaluate(model, device, validate_loader, criterion)\n",
        "    statistics['eval_loss'].append(validate_loss)\n",
        "    # 等train数据完整过了一遍再进行评估\n",
        "    logging.info(\n",
        "      f'epoch={epoch} finish, time={time.time()-start_time:.3f}s, train_loss={train_loss}, validate_loss={validate_loss}'\n",
        "      f', with lr={current_lr}'\n",
        "    )\n",
        "\n",
        "    early_stopping(validate_loss)\n",
        "    if early_stopping.stop:\n",
        "      logging.info(f'early stoping')\n",
        "      break\n",
        "\n",
        "    epoch += 1\n",
        "    start_time = time.time()\n",
        "    train_sampler.reset_state()\n",
        "  \n",
        "  # Save model\n",
        "  statistics['epoch'] = epoch\n",
        "  checkpoint = {\n",
        "    'epoch': epoch,\n",
        "    'model': model.state_dict(),\n",
        "    'sampler': train_sampler.state_dict(),\n",
        "    'early_stopping': early_stopping.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "  }\n",
        "  torch.save(checkpoint, resume_checkpoint_path)\n",
        "  torch.save(statistics, statistics_path)\n",
        "  logging.info(f'save model and statistics to {checkpoints_dir}')\n",
        "logging.info(f'-------train loop ends, time={time.time()-loop_start_time:.3f}s-------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm /content/logs -r"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "yui_colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d5c8e674f5dfa726cbc4d7a25209bb75f43fdf268afb841d4cc164f7f4d4aeee"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
