{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-0864_dB5Mv",
        "outputId": "233c44ec-b337-4dc8-ade8-a64753d028d4"
      },
      "outputs": [],
      "source": [
        "!lsb_release -a\n",
        "# !cat /etc/shells\n",
        "# !echo $SHELL\n",
        "!cat /proc/cpuinfo \n",
        "!free -m\n",
        "!nvidia-smi\n",
        "\n",
        "# %pip install --upgrade pip\n",
        "%pip install mir_eval librosa h5py\n",
        "# %pip install torch==1.10.2 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "%pip install note_seq==0.0.3 transformers  scikit-learn  pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import shutil\n",
        "\n",
        "!rm /kaggle/working/yui/ -r\n",
        "shutil.copytree(r'../input/yui-code/yui_py37', r'/kaggle/working/yui')\n",
        "sys.path.insert(0, r'/kaggle/working/yui')\n",
        "shutil.copytree(r'../input/yui-checkpoints', r'/kaggle/working/checkpoints')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import T5ForConditionalGeneration, T5Config\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "\n",
        "from datasets import MaestroDataset3, MaestroSampler2, collate_fn\n",
        "import vocabularies\n",
        "import config\n",
        "from config.data import YuiConfigPro\n",
        "import utils\n",
        "from train import train, evaluate\n",
        "\n",
        "resume = True\n",
        "\n",
        "\n",
        "# config\n",
        "cf = YuiConfigPro(\n",
        "  DATASET_DIR=r'/kaggle/input/maestrov300-hdf5/',\n",
        "  DATAMETA_NAME=r'maestro-v3.0.0.csv',\n",
        "  WORKSPACE=r'/kaggle/working/',\n",
        "  CUDA=True,\n",
        "  NUM_EPOCHS=30,\n",
        "  NUM_WORKERS=2,\n",
        "  BATCH_SIZE=12,  \n",
        "  TRAIN_ITERATION=600,\n",
        ")\n",
        "# 一般是p100，显存16GB\n",
        "# batch_size 小一点快点进入gpu处理似乎还好一些\n",
        "# batch_size=26时，iter50大约2.5分钟，差不多15分钟保存一次\n",
        "\n",
        "# Arugments & parameters\n",
        "workspace = cf.WORKSPACE\n",
        "batch_size = cf.BATCH_SIZE\n",
        "device = torch.device('cuda') if cf.CUDA and torch.cuda.is_available() else torch.device('cpu')\n",
        "num_workers = cf.NUM_WORKERS\n",
        "\n",
        "class Adafactor2(Adafactor):\n",
        "  def __init__(\n",
        "    self,\n",
        "    params,\n",
        "    lr=None,\n",
        "    eps=(1e-30, 1e-3),\n",
        "    clip_threshold=1.0,\n",
        "    decay_rate=-0.8,\n",
        "    beta1=None,\n",
        "    weight_decay=0.0,\n",
        "    scale_parameter=True,\n",
        "    relative_step=True,\n",
        "    warmup_init=False,\n",
        "  ):\n",
        "    super().__init__(params, lr, eps, clip_threshold, decay_rate, beta1, weight_decay, scale_parameter, relative_step, warmup_init)\n",
        "\n",
        "  @staticmethod\n",
        "  def _get_lr(param_group, param_state):\n",
        "    rel_step_sz = param_group[\"lr\"]\n",
        "    if param_group[\"relative_step\"]:\n",
        "      min_step = 1e-6 * param_state[\"step\"] if param_group[\"warmup_init\"] else 1e-3\n",
        "      exp_lr = math.exp(-(6.45 + param_state[\"step\"] / 3e4))\n",
        "      # 这个值将在step=[1500,30000]从1.5e-3降到9.6e-4\n",
        "      rel_step_sz = min(min_step, exp_lr)\n",
        "    if param_group[\"scale_parameter\"]:\n",
        "      rel_step_sz *= max(param_group[\"eps\"][1], param_state[\"RMS\"])\n",
        "    return rel_step_sz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checkpoint & Log\n",
        "# 单独放置，否则多次创建logger会有多个重复输出\n",
        "\n",
        "checkpoints_dir = os.path.join(workspace, 'checkpoints')\n",
        "utils.create_folder(checkpoints_dir)\n",
        "logs_dir = os.path.join(workspace, 'logs')\n",
        "utils.create_logging(logs_dir, f'train', filemode='w', with_time=True)\n",
        "resume_checkpoint_path = os.path.join(checkpoints_dir, 'model_resume.pt')\n",
        "best_checkpoint_path = os.path.join(checkpoints_dir, 'model_best.pt')\n",
        "statistics_path = os.path.join(checkpoints_dir, 'statistics.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Codec & Vocabulary\n",
        "codec = vocabularies.build_codec(cf)\n",
        "vocabulary = vocabularies.Vocabulary(cf, codec.num_classes, extra_ids=cf.EXTRA_IDS)\n",
        "t5_config_map = config.build_t5_config(\n",
        "  d_model=cf.NUM_MEL_BINS,\n",
        "  vocab_size=vocabulary.vocab_size,\n",
        "  max_length=cf.MAX_TARGETS_LENGTH,\n",
        ")\n",
        "# 简化模型，否则根本训练不动\n",
        "utils.show_gpu_info()\n",
        "\n",
        "logging.info(cf) \n",
        "if device.type == 'cuda':\n",
        "  logging.info('Using GPU.')\n",
        "  logging.info(f'GPU number: {torch.cuda.device_count()}')\n",
        "else:\n",
        "  logging.info('Using CPU.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset\n",
        "meta_path = os.path.join(cf.DATASET_DIR, cf.DATAMETA_NAME)\n",
        "\n",
        "train_sampler = MaestroSampler2(meta_path, 'train', batch_size=batch_size, config=cf, max_iter_num=cf.TRAIN_ITERATION)\n",
        "train_dataset = MaestroDataset3(cf.DATASET_DIR, cf, codec, vocabulary, meta_file=cf.DATAMETA_NAME)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_sampler=train_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "validate_sampler = MaestroSampler2(meta_path, 'validation', batch_size=batch_size, config=cf, max_iter_num=-1)\n",
        "validate_loader = DataLoader(dataset=train_dataset, batch_sampler=validate_sampler, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)\n",
        "# pin_memory: 锁页内存，不会与虚存进行交换，转到gpu时快一些，但很容易超出gpu显存\n",
        "\n",
        "# Model\n",
        "t5_config = T5Config.from_dict(t5_config_map)\n",
        "logging.info(t5_config)\n",
        "model = T5ForConditionalGeneration(config=t5_config)\n",
        "logging.info(f'The model has {model.num_parameters():,} trainable parameters')\n",
        "# 17,896 for dev; 48,626,048 for pro; while T5-Small has 60 million parameters\n",
        "\n",
        "# Early stop\n",
        "early_stopping = utils.EarlyStopping(\n",
        "  best_path=best_checkpoint_path,\n",
        "  resume_path=resume_checkpoint_path,\n",
        "  patience=cf.OVERFIT_PATIENCE, \n",
        "  verbose=True\n",
        ")\n",
        "\n",
        "# Resume training\n",
        "resume_epoch = 0\n",
        "learning_rate = cf.LEARNING_RATE\n",
        "statistics = {\n",
        "  'epoch': 0,\n",
        "  'train_loss': [],\n",
        "  'eval_loss': []\n",
        "}\n",
        "\n",
        "# Loss function\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=cf.PAD_ID)\n",
        "\n",
        "# Optimizer\n",
        "# optimizer = Adafactor(model.parameters(), lr=learning_rate, scale_parameter=False, relative_step=False, warmup_init=False)\n",
        "optimizer = Adafactor2(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
        "scheduler = AdafactorSchedule(optimizer, learning_rate)\n",
        "\n",
        "if not resume:\n",
        "  ...\n",
        "  # 从头开始训练模型\n",
        "elif not os.path.isfile(resume_checkpoint_path):\n",
        "  logging.info(f'resume_checkpoint_path={resume_checkpoint_path} does not exist, train from scratch')\n",
        "elif not os.path.isfile(statistics_path):\n",
        "  logging.info(f'statistics_path={statistics_path} does not exist, train from scratch')\n",
        "else:\n",
        "  statistics = torch.load(statistics_path)\n",
        "  # 单独保存后面数据分析读取方便些\n",
        "  # raise FileNotFoundError(f'resume_checkpoint_path={resume_checkpoint_path} does not exist')\n",
        "  checkpoint = torch.load(resume_checkpoint_path)\n",
        "  # 以TRAIN_ITERATION为单位保存checkpoint\n",
        "  early_stopping.load_state_dict(checkpoint['early_stopping'])\n",
        "\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  train_sampler.load_state_dict(checkpoint['sampler'])\n",
        "  validate_sampler.epoch = train_sampler.epoch\n",
        "  # 二者epoch一致\n",
        "  resume_epoch = checkpoint['epoch']\n",
        "  # scheduler.get_lr 拿到的lr是个列表\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  logging.info(f'resume training with epoch={resume_epoch}')\n",
        "  logging.info(f'statistics = {statistics}')\n",
        "\n",
        "model.to(device)\n",
        "epoch = resume_epoch\n",
        "loop_start_time = time.time()\n",
        "start_time = time.time()\n",
        "logging.info(f'-------train loop starts, start_time={start_time:.3f}s-------')\n",
        "\n",
        "# for epoch in range(resume_epoch, cf.NUM_EPOCHS):\n",
        "while epoch < cf.NUM_EPOCHS:\n",
        "  train_loss = train(model, device, train_loader, criterion, optimizer, scheduler, accumulation_steps=cf.accumulation_steps)\n",
        "  statistics['train_loss'].append(train_loss)\n",
        "  current_lr = scheduler.get_lr()\n",
        "\n",
        "  # 训练数据完整采样一轮\n",
        "  if train_sampler.epoch > epoch:\n",
        "    validate_sampler.reset_state()\n",
        "    validate_loss = evaluate(model, device, validate_loader, criterion)\n",
        "    statistics['eval_loss'].append(validate_loss)\n",
        "    # 等train数据完整过了一遍再进行评估\n",
        "    logging.info(\n",
        "      f'epoch={epoch} finish, time={time.time()-start_time:.3f}s, train_loss={train_loss}, validate_loss={validate_loss}'\n",
        "      f', with lr={current_lr}'\n",
        "    )\n",
        "\n",
        "    early_stopping(validate_loss)\n",
        "    if early_stopping.stop:\n",
        "      logging.info(f'early stoping')\n",
        "      break\n",
        "\n",
        "    epoch += 1\n",
        "    start_time = time.time()\n",
        "    train_sampler.reset_state()\n",
        "  \n",
        "  # Save model\n",
        "  statistics['epoch'] = epoch\n",
        "  checkpoint = {\n",
        "    'epoch': epoch,\n",
        "    'model': model.state_dict(),\n",
        "    'sampler': train_sampler.state_dict(),\n",
        "    'early_stopping': early_stopping.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "  }\n",
        "  torch.save(checkpoint, resume_checkpoint_path)\n",
        "  torch.save(statistics, statistics_path)\n",
        "  logging.info(f'save model and statistics to {checkpoints_dir}')\n",
        "logging.info(f'-------train loop ends, time={time.time()-loop_start_time:.3f}s-------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm /content/logs -r"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "yui_colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d5c8e674f5dfa726cbc4d7a25209bb75f43fdf268afb841d4cc164f7f4d4aeee"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
